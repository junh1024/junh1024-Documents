# Atmos Music Mixing Notes

## Introduction
These are my mixing notes for my [Atmos Music Collection](https://github.com/junh1024/junh1024-Documents/blob/master/Music/Atmos%20Music%20Collection.md#introduction) . Downloads in the previous link.

## General volume
So near the end of Nov 2020, I was told about a cheap Atmos encoder. I spent a few days setting up my acc & then the following few weeks to rework my old 3D projects to be less hax & sound better. I also felt the need to get more stems to remix into songs, to form a substantial collection rather than just a few songs.

- Optinuum had little changes.
- Katamari Stars had major infrastructure changes. It is now back to surround, but now with std 15.1 routing. The levels were re-balanced. Replacing the 3oA panners with 151 panner via RPP editing was compatible, but the ranges were slightly different so needed a bit of adjustment. Slightly more sophisticated string upscaling. Strings slightly lowered.
- AC4 Blockade. Also had major changes. Since people will now listen with >5 speakers, I replaced the cheap 4ch reverb upscaled to 8ch, with a real 10ch reverb (FdnReverb). I discovered more notation errors with strings & horns so I fixed them, but prolly still not totally accurate. A few panning changes. Slightly more sophisticated string upscaling.
- Amapola. A few panning & notation changes.


## Cello Concerto
Overall, I liked it. I found it on the CMT page, and was expecting it to be something boring like a Mozart or Beethoven symphony, but it got my interest. Maybe cuz it's in minor. The introduction was a bit weak but due to stockholm syndrome I'm now a bit ambivalent about it. It concerto also sounds a bit like Greig's Piano concerto, mainly cuz they're both in Am. There is a subforum on the CMT site for the concerto. Unfortunately, there aren't many mixing retrospectives, apart from "eggshell"

Like me, eggshell applied reverb, compression, but doesn't want to spend too much time on automation. The brass is panned to the back, but this also includes a tuba, but the Tuba does bass duty (bass should at the front). Ethan then gave me a Tuba MIDI, which I then changed to a Bass Guitar. Which now makes more sense. I then realized that due to the length of the Concerto, that it would totally dominate the length of a pop compilation.

So I started marking possible cuts & testing them out. The cadenza is easy to cut since there's only 1 instrument, but most other sections are hard. I started cutting from the end. Cutting is hard since there's some key changes. I need to use my knowledge of cadences, but Bending rules like 5 > 1m. The cutting is based on cutting out sections of theme 1. The intro was also shortened so that the cello solo comes in within 1 min, (like Greig's Piano Concerto), rather than within 2.

Despite spending some effort finding & explaining cuts, Ethan preferred to leave his concerto uncut. A few weeks later, I found some musopen sessions on the Internet Archive, so that it won't be out of place with a 16m length, as part of a classical compilation rather than a pop compilation.

I thought that Adding in section dynamics by comparing to Ethan's 2020 mix would be enough, but comparing sections the instruments balance is still off. So I need to do bus automation. With section bus automation, I did a reduced range of automation compared to Ethan. For me, The main thing is the strings-wind balance. It doesn't matter if the brass is a bit soft. It should sit in the mix, and not be too distracting. Since the brass is @back, this adds additional emphasis, so you can deliberately mix it slightly lower. Due to reduced range, my string bed is a bit higher than Ethan's during the cello solo sections. I prefer this, but mainly cuz I'm used to hearing the whole mix w/o automation. Since Ethan knows the most about his work, I sorta expected no need for automation of his Cello solo track. This isn't the case and it needs some dynamics work.

After a few weeks of leaving it, I realized the front may have too much reverb when downmixed to 51/71. So I need to change the reverb from 91 to 71.

## Pure Luxury
Again, found on the Cambridge MT site. I was expecting another mediocre pop piece, but I liked it. At >100 tracks, I thought it must be the production of an accomplished artist. I started getting ideas for surround as I listened to the song. But when I got the stems, I was slightly disappointed by some of the vox SQ, Since "Vox-stacked-ahhs-all" was all in downmixed stereo. The artist didn't have further separation due to being overdubbed on hardware, but I really wanted the idea to work. I thought about Melodyne.

Initially I was using Melodyne wrong by doing too much note manipulation & using stereo input. Then I did 2x mono input & that was better. I wrote a Melodyne quickstart guide shortly after. Ingesting the stems took several weeks. There were several issues with the vox. There are stems labelled L & R, which are 2x stereo. So space could be saved by combining them. Some are panned at different widths, so combining them may change volume. Some are clipped. So I had to recreate them by gaining the opposite channel. sox somehow doesn't do fp32 properly (it works in int32 & clips at 0dB), so I have to reduce all vox by 6dB to avoid re-clipping. I then decided to reduce the volume of all other stems for consistency. I then recreated some reverbs & synths for MIDI note keytrack panning.

I had another idea for The blip percussion, have blips alternating L&R , and travelling through to back & height, I thought would be too complex to implement & almost gave up, but again, loop_slicer_6 to the rescue.

Having the 'stop' clips come from different speakers in 716 was also another early idea I had. But it's fraught with implementation issues. The 51 legacy presentation downmixes side & height side into rear channels so a F S B surround delay won't sound symmetrical in 51. The samples are also done on a cycle length of 8. mcfx gain_delay also has a very low max delay limit. In the end, I settled on a cubular stop arrangement, which works well with 51 downmix &can work well with readelay + loop_slicer_6

Implementing this was a bit tricky. The stop track begins on a half-beat. So I need to listen to other tracks to hear the context. So the main vox begins on beat one, then the stop repeats on 1/8ths. For the simplest implementation, this means that the delayed stop should start on the right then progress backwards. So I reversed the clips of stop so that it starts R L. Readelay is set to feedback at 0dB, so I need to bypass the FX when I want it to stop. Luckily, the buffers are also cleared when it gets un- bypassed so I can have it delay a new section.

## Wahrheit
I was glad when I got this MT in Nov 2017 that there were lots of BVs, so that I can pan them into surround. Including a studio choir and a gospel choir. But I was a bit overwhelmed about which to use, and the arrangement. I left the project for a few years. In 2021, there is a need for Atmos material so I open this project, and start working on it again. After working on Earth Song a few weeks ago, I'm a bit clearer on what to do. BVs at the back. Vocal fills at the top. I find that the gospel choir has too much reverb, so I can skip that. Like ES, the idea is to build up the song towards the end. This means muting clips for a faux-crescendo, and rearranging clips to make melodic sense & consistency. Applies to BVs & choir.

## Peer Gynt suite
So since getting stems from a game/app might be hard, I did a search on "Solveig's Song", which led to the Peer Gynt page on Wikipedia. I noticed that the audio samples were by Musopen. Well, turns out they recorded a bunch of classical works, which includes "Peer Gynt" suite 1 & a lot of other works. With session files on Internet Archive. Since they're public domain, there's no need to ask for permission. So I downloaded them to make a surround remix. 

The files aren't named in a sensible order. Like "1st violin B_02F" isn't necessarily from the same take as "bassoon_02". Since some instruments may be omitted from certain songs since they're inactive, N means the N-th occurrence of that instrument in this pack. Which is not helpful for assembling a project in another DAW from scratch. The takes are also not in movement order.

I had to guess how it should be edited. The converted PTFs seem to be just imports, and little editing. They also seem to have misalignment in some tracks. I decided to have a program of 4 songs for editing convenience. The audio comes in 7 takes, or about 2 takes per song. The 1st take is usually a complete run. The 2nd take is partial so I need to figure out what mistakes were made. Because the 2nd take starts partway in, the mistake is that length inwards of the 1st take. The mistake is usually mistimed winds. Contra bassoon & harp clips were also included, but are actually not used (the mics are active due to bleed). I checked wiki & the score to confirm this. I did the breaks such that there's silence 5s long from end of last note's tail, to 1st note of next song.

The bassoon mic is almost redundant since it bleeds into the other wind mics at a high level. There are 7 room mics, but I only used Decca C. I did a small boost to most of the strings, and some cuts to winds & brass. Compared to Ethan's concerto, there is almost no need to spend days on manual automation since the conductor is controlling the dynamics and the orchestra reacting to itself. However, a big downside is the high bleed since the orchestra is recorded as a whole, not segregated.

When I finished editing, the next step is surround panning. As usual, I put the brass to the back. But during brass solo sections, there is significant bleed to the front, as most other mics pick them up, to the point that solo brass is almost front-heavy. I thought my FFTMT would do the job of fixing the bleed, but it doesn't really fix the bleed, until it also removes strings. So I set it to a moderate amount. There is enough bleed even w/o a surround reverb. Initially I had a separated F/B reverb ReaVerbate for front & ambiverb for back, but I tot a difference in character would be inconsistent so I removed ReaVerbate from the front.

My test section is the solo horn call in mvt1. You can remove some bleed with EQ, but that only works for the minority of the instruments since most of the occupy the midrange which the horn is also occupying. So then I had the idea of using the stereo info in the instrument pairs to remove the horn. This sorta relies on knowing the instrument/mic placement via the orchestra setup map (which seems to be slightly wrong at times). So I upscale to 5.0, keep the channel which focuses on the instrument, turn C down, and reject the other channels. There is chamnix2 use for post-gain (to keep the loudness of the original instrument) and mapping to LRC. FFT surround upscaling is CPU intensive so I made a lite/small version of my 2>5 upmix (unfortunately, the saving is only about 10%). I also tried ReaFIR for EQ, since the curves are sharper, but the difference with IIR EQ is small (and it uses more CPU), so regular EQ it is. This technique was applied to all strings & some winds. Overall, the horn rejection is 3-6dB for each instrument & master mix. Which is enough to move the horn from mostly front to mostly back (hopefully). 

The next step is to remove what should be front from the back. Since not all of the brass is stereo, I can't use my upscaler for all of them. I want to remove the timpani from the back, and the timpani is relatively isolated. I apply a lowpass to it, and send it to the brass bus. I need 2 instances of FFTMT to reduce the timpani from the brass. Care needs to be taken for IO routing to pass through audio, so that they both work simultaneously.

## Tchaikovsky Symphony 6

With this suite, I had a logic project to guide my editing, but getting an actual logic conversion working in RPR was a "long" and unsuccessful journey. Converted PTF to RPPs aren't very useful as usual (no editing done). The logic files have a preview in windows, but still not ttly useful. I boot up my OSX 10.6 VM. Logic 8 express eventually opens up the logic documents after a few errors. But it took several tries to get the audio clips looking right, since I tried to load LQ stubs instead of 96/24 in logic initially. It seems that logic stores fseek offsets in documents as for WAV files, so only files of exactly the same sample format will do.

AAF & OMF converts were unreliable to RPR. In the end, I settled for screenshots of the edits in logic (with filenames/takes clearly visible) & recreated them in RPR. Although the length didn't always match for some reason.

